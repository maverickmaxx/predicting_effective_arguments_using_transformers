{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Text classification with the torchtext library\n",
        "==================================\n",
        "\n",
        "In this tutorial, we will show how to use the torchtext library to build the dataset for the text classification analysis. Users will have the flexibility to\n",
        "\n",
        "   - Access to the raw data as an iterator\n",
        "   - Build data processing pipeline to convert the raw text strings into ``torch.Tensor`` that can be used to train the model\n",
        "   - Shuffle and iterate the data with `torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Access to the raw dataset iterators\n",
        "-----------------------------------\n",
        "\n",
        "The torchtext library provides a few raw dataset iterators, which yield the raw text strings. For example, the ``AG_NEWS`` dataset iterators yield the raw data as a tuple of label and text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "#from torchtext.datasets import AG_NEWS\n",
        "#train_iter = AG_NEWS(split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('../data/train_berkeley.csv') \n",
        "test_df = pd.read_csv('../data/test_berkeley.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\waqasali\\AppData\\Local\\Temp\\ipykernel_20208\\1867476981.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['label'][i] = 0\n",
            "C:\\Users\\waqasali\\AppData\\Local\\Temp\\ipykernel_20208\\1867476981.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['label'][i] = 2\n",
            "C:\\Users\\waqasali\\AppData\\Local\\Temp\\ipykernel_20208\\1867476981.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_df['label'][i] = 1\n",
            "C:\\Users\\waqasali\\AppData\\Local\\Temp\\ipykernel_20208\\1867476981.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['label'][i] = 0\n",
            "C:\\Users\\waqasali\\AppData\\Local\\Temp\\ipykernel_20208\\1867476981.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['label'][i] = 1\n",
            "C:\\Users\\waqasali\\AppData\\Local\\Temp\\ipykernel_20208\\1867476981.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['label'][i] = 2\n"
          ]
        }
      ],
      "source": [
        "train_df['label'] = 0\n",
        "for i in range(len(train_df)):\n",
        "    if train_df.discourse_effectiveness[i] == 'Adequate':\n",
        "        train_df['label'][i] = 0 \n",
        "    elif train_df.discourse_effectiveness[i] == 'Effective':    \n",
        "        train_df['label'][i] = 1\n",
        "    elif train_df.discourse_effectiveness[i] == 'Ineffective':    \n",
        "        train_df['label'][i] = 2\n",
        "\n",
        "test_df['label'] = 0\n",
        "for i in range(len(test_df)):\n",
        "    if test_df.discourse_effectiveness[i] == 'Adequate':\n",
        "        test_df['label'][i] = 0 \n",
        "    elif test_df.discourse_effectiveness[i] == 'Effective':    \n",
        "        test_df['label'][i] = 1\n",
        "    elif test_df.discourse_effectiveness[i] == 'Ineffective':    \n",
        "        test_df['label'][i] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0013cc385424</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9704a709b505</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>c22adee811b6</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>a10d361e54e4</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>If life was on Mars, we would know by now. The...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>db3e453ec4e2</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>People thought that the face was formed by ali...</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33292</th>\n",
              "      <td>36760</td>\n",
              "      <td>9f63b687e76a</td>\n",
              "      <td>FFA381E58FC6</td>\n",
              "      <td>For many people they don't like only asking on...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33293</th>\n",
              "      <td>36761</td>\n",
              "      <td>9d5bd7d86212</td>\n",
              "      <td>FFA381E58FC6</td>\n",
              "      <td>also people have different views and opinions ...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33294</th>\n",
              "      <td>36762</td>\n",
              "      <td>f1b78becd573</td>\n",
              "      <td>FFA381E58FC6</td>\n",
              "      <td>Advice is something that can impact a persons ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33295</th>\n",
              "      <td>36763</td>\n",
              "      <td>cc184624ca8e</td>\n",
              "      <td>FFA381E58FC6</td>\n",
              "      <td>someone can use everything that many people sa...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Ineffective</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33296</th>\n",
              "      <td>36764</td>\n",
              "      <td>c8a973681feb</td>\n",
              "      <td>FFA381E58FC6</td>\n",
              "      <td>In conclusion asking for an opinion can be ben...</td>\n",
              "      <td>Concluding Statement</td>\n",
              "      <td>Ineffective</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33297 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  discourse_id      essay_id  \\\n",
              "0               0  0013cc385424  007ACE74B050   \n",
              "1               1  9704a709b505  007ACE74B050   \n",
              "2               2  c22adee811b6  007ACE74B050   \n",
              "3               3  a10d361e54e4  007ACE74B050   \n",
              "4               4  db3e453ec4e2  007ACE74B050   \n",
              "...           ...           ...           ...   \n",
              "33292       36760  9f63b687e76a  FFA381E58FC6   \n",
              "33293       36761  9d5bd7d86212  FFA381E58FC6   \n",
              "33294       36762  f1b78becd573  FFA381E58FC6   \n",
              "33295       36763  cc184624ca8e  FFA381E58FC6   \n",
              "33296       36764  c8a973681feb  FFA381E58FC6   \n",
              "\n",
              "                                          discourse_text  \\\n",
              "0      Hi, i'm Isaac, i'm going to be writing about h...   \n",
              "1      On my perspective, I think that the face is a ...   \n",
              "2      I think that the face is a natural landform be...   \n",
              "3      If life was on Mars, we would know by now. The...   \n",
              "4      People thought that the face was formed by ali...   \n",
              "...                                                  ...   \n",
              "33292  For many people they don't like only asking on...   \n",
              "33293  also people have different views and opinions ...   \n",
              "33294  Advice is something that can impact a persons ...   \n",
              "33295  someone can use everything that many people sa...   \n",
              "33296  In conclusion asking for an opinion can be ben...   \n",
              "\n",
              "             discourse_type discourse_effectiveness  label  \n",
              "0                      Lead                Adequate      0  \n",
              "1                  Position                Adequate      0  \n",
              "2                     Claim                Adequate      0  \n",
              "3                  Evidence                Adequate      0  \n",
              "4              Counterclaim                Adequate      0  \n",
              "...                     ...                     ...    ...  \n",
              "33292                 Claim                Adequate      0  \n",
              "33293                 Claim                Adequate      0  \n",
              "33294              Position                Adequate      0  \n",
              "33295              Evidence             Ineffective      2  \n",
              "33296  Concluding Statement             Ineffective      2  \n",
              "\n",
              "[33297 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>218bfd96197d</td>\n",
              "      <td>0168325D0E24</td>\n",
              "      <td>Being in a car is how we transport ourselves t...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>70</td>\n",
              "      <td>599e5e16e9ed</td>\n",
              "      <td>0168325D0E24</td>\n",
              "      <td>Well Paris has enforced a driving ban to help ...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71</td>\n",
              "      <td>a398be97f2b7</td>\n",
              "      <td>0168325D0E24</td>\n",
              "      <td>It actually helped having cars stop driving on...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72</td>\n",
              "      <td>38a6679de2ed</td>\n",
              "      <td>0168325D0E24</td>\n",
              "      <td>\"Recent studies suggest that Americans are buy...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>73</td>\n",
              "      <td>f1cc93a81a32</td>\n",
              "      <td>0168325D0E24</td>\n",
              "      <td>In the more populated citys, people are using ...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Effective</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>36725</td>\n",
              "      <td>8d66664512a0</td>\n",
              "      <td>FE3CA06DDCA1</td>\n",
              "      <td>they might want to give the on who is giving t...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>36726</td>\n",
              "      <td>4c649f487587</td>\n",
              "      <td>FE3CA06DDCA1</td>\n",
              "      <td>they are give you as much detail as they have ...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>36727</td>\n",
              "      <td>b887de306ae7</td>\n",
              "      <td>FE3CA06DDCA1</td>\n",
              "      <td>They will want to give you all the information...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3466</th>\n",
              "      <td>36728</td>\n",
              "      <td>54851ec259ee</td>\n",
              "      <td>FE3CA06DDCA1</td>\n",
              "      <td>If a person wants good advice they will want t...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>36729</td>\n",
              "      <td>b7c27670f3bc</td>\n",
              "      <td>FE3CA06DDCA1</td>\n",
              "      <td>why you need advice you will talk more then th...</td>\n",
              "      <td>Concluding Statement</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3468 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  discourse_id      essay_id  \\\n",
              "0             69  218bfd96197d  0168325D0E24   \n",
              "1             70  599e5e16e9ed  0168325D0E24   \n",
              "2             71  a398be97f2b7  0168325D0E24   \n",
              "3             72  38a6679de2ed  0168325D0E24   \n",
              "4             73  f1cc93a81a32  0168325D0E24   \n",
              "...          ...           ...           ...   \n",
              "3463       36725  8d66664512a0  FE3CA06DDCA1   \n",
              "3464       36726  4c649f487587  FE3CA06DDCA1   \n",
              "3465       36727  b887de306ae7  FE3CA06DDCA1   \n",
              "3466       36728  54851ec259ee  FE3CA06DDCA1   \n",
              "3467       36729  b7c27670f3bc  FE3CA06DDCA1   \n",
              "\n",
              "                                         discourse_text        discourse_type  \\\n",
              "0     Being in a car is how we transport ourselves t...                  Lead   \n",
              "1     Well Paris has enforced a driving ban to help ...              Evidence   \n",
              "2     It actually helped having cars stop driving on...                 Claim   \n",
              "3     \"Recent studies suggest that Americans are buy...              Evidence   \n",
              "4     In the more populated citys, people are using ...                 Claim   \n",
              "...                                                 ...                   ...   \n",
              "3463  they might want to give the on who is giving t...                 Claim   \n",
              "3464  they are give you as much detail as they have ...                 Claim   \n",
              "3465  They will want to give you all the information...              Evidence   \n",
              "3466  If a person wants good advice they will want t...              Evidence   \n",
              "3467  why you need advice you will talk more then th...  Concluding Statement   \n",
              "\n",
              "     discourse_effectiveness  label  \n",
              "0                   Adequate      0  \n",
              "1                   Adequate      0  \n",
              "2                   Adequate      0  \n",
              "3                   Adequate      0  \n",
              "4                  Effective      1  \n",
              "...                      ...    ...  \n",
              "3463                Adequate      0  \n",
              "3464                Adequate      0  \n",
              "3465                Adequate      0  \n",
              "3466                Adequate      0  \n",
              "3467                Adequate      0  \n",
              "\n",
              "[3468 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter_list = []\n",
        "for i in range(len(train_df)):\n",
        "    train_iter_list.append([train_df.label[i], train_df.discourse_text[i]])\n",
        "train_iter = (x for x in train_iter_list) \n",
        "train_iter = torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe(train_iter)\n",
        "\n",
        "test_iter_list = []\n",
        "for i in range(len(test_df)):\n",
        "    test_iter_list.append([test_df.label[i], test_df.discourse_text[i]])\n",
        "test_iter = (x for x in test_iter_list) \n",
        "test_iter = torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe(test_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::\n",
        "\n",
        "    next(train_iter)\n",
        "    >>> (3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - \n",
        "    Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green \n",
        "    again.\")\n",
        "\n",
        "    next(train_iter)\n",
        "    >>> (3, 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private \n",
        "    investment firm Carlyle Group,\\\\which has a reputation for making well-timed \n",
        "    and occasionally\\\\controversial plays in the defense industry, has quietly \n",
        "    placed\\\\its bets on another part of the market.')\n",
        "\n",
        "    next(train_iter)\n",
        "    >>> (3, \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring \n",
        "    crude prices plus worries\\\\about the economy and the outlook for earnings are \n",
        "    expected to\\\\hang over the stock market next week during the depth of \n",
        "    the\\\\summer doldrums.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare data processing pipelines\n",
        "---------------------------------\n",
        "\n",
        "We have revisited the very basic components of the torchtext library, including vocab, word vectors, tokenizer. Those are the basic data processing building blocks for raw text string.\n",
        "\n",
        "Here is an example for typical NLP data processing with tokenizer and vocabulary. The first step is to build a vocabulary with the raw training dataset. Users can have a customized vocab by setting up arguments in the constructor of the Vocab class. For example, the minimum frequency ``min_freq`` for the tokens to be included.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "#train_iter = AG_NEWS(split='train')\n",
        "counter = Counter()\n",
        "for (label, line) in train_iter:\n",
        "    counter.update(tokenizer(line))\n",
        "vocab = vocab(counter, min_freq = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27810"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The vocabulary block converts a list of tokens into integers.\n",
        "\n",
        "::\n",
        "\n",
        "    [vocab[token] for token in ['here', 'is', 'an', 'example']]\n",
        "    >>> [476, 22, 31, 5298]\n",
        "\n",
        "Prepare the text processing pipeline with the tokenizer and vocabulary. The text and label pipelines will be used to process the raw data strings from the dataset iterators.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_pipeline = lambda x: int(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The text pipeline converts a text string into a list of integers based on the lookup table defined in the vocabulary. The label pipeline converts the label into integers. For example,\n",
        "\n",
        "::\n",
        "\n",
        "    text_pipeline('here is the an example')\n",
        "    >>> [475, 21, 2, 30, 5286]\n",
        "    label_pipeline('10')\n",
        "    >>> 9\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate data batch and iterator \n",
        "--------------------------------\n",
        "\n",
        "`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader>`__\n",
        "is recommended for PyTorch users (a tutorial is `here <https://pytorch.org/tutorials/beginner/data_loading_tutorial.html>`__).\n",
        "It works with a map-style dataset that implements the ``getitem()`` and ``len()`` protocols, and represents a map from indices/keys to data samples. It also works with an iterable dataset with the shuffle argument of ``False``.\n",
        "\n",
        "Before sending to the model, ``collate_fn`` function works on a batch of samples generated from ``DataLoader``. The input to ``collate_fn`` is a batch of data with the batch size in ``DataLoader``, and ``collate_fn`` processes them according to the data processing pipelines declared previously. Pay attention here and make sure that ``collate_fn`` is declared as a top level def. This ensures that the function is available in each worker.\n",
        "\n",
        "In this example, the text entries in the original data batch input are packed into a list and concatenated as a single tensor for the input of ``nn.EmbeddingBag``. The offset is a tensor of delimiters to represent the beginning index of the individual sequence in the text tensor. Label is a tensor saving the labels of indidividual text entries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)    \n",
        "\n",
        "#train_iter = AG_NEWS(split='train')\n",
        "#dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter_list = []\n",
        "for i in range(len(train_df)):\n",
        "    train_iter_list.append([train_df.label[i], train_df.discourse_text[i]])\n",
        "train_iter = (x for x in train_iter_list) \n",
        "train_iter = torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe(train_iter)\n",
        "\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the model\n",
        "----------------\n",
        "\n",
        "The model is composed of the `nn.EmbeddingBag <https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag>`__ layer plus a linear layer for the classification purpose. ``nn.EmbeddingBag`` with the default mode of \"mean\" computes the mean value of a “bag” of embeddings. Although the text entries here have different lengths, nn.EmbeddingBag module requires no padding here since the text lengths are saved in offsets.\n",
        "\n",
        "Additionally, since ``nn.EmbeddingBag`` accumulates the average across\n",
        "the embeddings on the fly, ``nn.EmbeddingBag`` can enhance the\n",
        "performance and memory efficiency to process a sequence of tensors.\n",
        "\n",
        "![](../_static/img/text_sentiment_ngrams_model.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initiate an instance\n",
        "--------------------\n",
        "\n",
        "The ``AG_NEWS`` dataset has four labels and therefore the number of classes is four.\n",
        "\n",
        "::\n",
        "\n",
        "   1 : World\n",
        "   2 : Sports\n",
        "   3 : Business\n",
        "   4 : Sci/Tec\n",
        "\n",
        "We build a model with the embedding dimension of 64. The vocab size is equal to the length of the vocabulary instance. The number of classes is equal to the number of labels,\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter_list = []\n",
        "for i in range(len(train_df)):\n",
        "    train_iter_list.append([train_df.label[i], train_df.discourse_text[i]])\n",
        "train_iter = (x for x in train_iter_list) \n",
        "train_iter = torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe(train_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define functions to train the model and evaluate results.\n",
        "---------------------------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split the dataset and run the model\n",
        "-----------------------------------\n",
        "\n",
        "Since the original ``AG_NEWS`` has no valid dataset, we split the training\n",
        "dataset into train/valid sets with a split ratio of 0.95 (train) and\n",
        "0.05 (valid). Here we use\n",
        "`torch.utils.data.dataset.random_split <https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split>`__\n",
        "function in PyTorch core library.\n",
        "\n",
        "`CrossEntropyLoss <https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss>`__\n",
        "criterion combines ``nn.LogSoftmax()`` and ``nn.NLLLoss()`` in a single class.\n",
        "It is useful when training a classification problem with C classes.\n",
        "`SGD <https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html>`__\n",
        "implements stochastic gradient descent method as the optimizer. The initial\n",
        "learning rate is set to 5.0.\n",
        "`StepLR <https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR>`__\n",
        "is used here to adjust the learning rate through epochs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter_list = []\n",
        "for i in range(len(train_df)):\n",
        "    train_iter_list.append([train_df.label[i], train_df.discourse_text[i]])\n",
        "train_iter = (x for x in train_iter_list) \n",
        "train_iter = torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe(train_iter)\n",
        "\n",
        "test_iter_list = []\n",
        "for i in range(len(test_df)):\n",
        "    test_iter_list.append([test_df.label[i], test_df.discourse_text[i]])\n",
        "test_iter = (x for x in test_iter_list) \n",
        "test_iter = torch.utils.data.datapipes.iter.grouping.ShardingFilterIterDataPipe(test_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time:  5.14s | valid accuracy    0.603 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time:  5.65s | valid accuracy    0.610 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time:  5.68s | valid accuracy    0.615 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time:  5.55s | valid accuracy    0.613 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time:  5.62s | valid accuracy    0.620 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time:  6.05s | valid accuracy    0.614 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time:  5.29s | valid accuracy    0.621 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time:  5.33s | valid accuracy    0.617 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time:  6.17s | valid accuracy    0.617 \n",
            "-----------------------------------------------------------\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time:  5.51s | valid accuracy    0.617 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "#train_iter, test_iter = AG_NEWS()\n",
        "train_dataset = list(train_iter)\n",
        "test_dataset = list(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the model on GPU with the following printout:\n",
        "\n",
        "::\n",
        "\n",
        "       | epoch   1 |   500/ 1782 batches | accuracy    0.684\n",
        "       | epoch   1 |  1000/ 1782 batches | accuracy    0.852\n",
        "       | epoch   1 |  1500/ 1782 batches | accuracy    0.877\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   1 | time:  8.33s | valid accuracy    0.867\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   2 |   500/ 1782 batches | accuracy    0.895\n",
        "       | epoch   2 |  1000/ 1782 batches | accuracy    0.900\n",
        "       | epoch   2 |  1500/ 1782 batches | accuracy    0.903\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   2 | time:  8.18s | valid accuracy    0.890\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   3 |   500/ 1782 batches | accuracy    0.914\n",
        "       | epoch   3 |  1000/ 1782 batches | accuracy    0.914\n",
        "       | epoch   3 |  1500/ 1782 batches | accuracy    0.916\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   3 | time:  8.20s | valid accuracy    0.897\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   4 |   500/ 1782 batches | accuracy    0.926\n",
        "       | epoch   4 |  1000/ 1782 batches | accuracy    0.924\n",
        "       | epoch   4 |  1500/ 1782 batches | accuracy    0.921\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   4 | time:  8.18s | valid accuracy    0.895\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   5 |   500/ 1782 batches | accuracy    0.938\n",
        "       | epoch   5 |  1000/ 1782 batches | accuracy    0.935\n",
        "       | epoch   5 |  1500/ 1782 batches | accuracy    0.937\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   5 | time:  8.16s | valid accuracy    0.902\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   6 |   500/ 1782 batches | accuracy    0.939\n",
        "       | epoch   6 |  1000/ 1782 batches | accuracy    0.939\n",
        "       | epoch   6 |  1500/ 1782 batches | accuracy    0.938\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   6 | time:  8.16s | valid accuracy    0.906\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   7 |   500/ 1782 batches | accuracy    0.941\n",
        "       | epoch   7 |  1000/ 1782 batches | accuracy    0.939\n",
        "       | epoch   7 |  1500/ 1782 batches | accuracy    0.939\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   7 | time:  8.19s | valid accuracy    0.903\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   8 |   500/ 1782 batches | accuracy    0.942\n",
        "       | epoch   8 |  1000/ 1782 batches | accuracy    0.941\n",
        "       | epoch   8 |  1500/ 1782 batches | accuracy    0.942\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch   8 | time:  8.16s | valid accuracy    0.904\n",
        "       -----------------------------------------------------------\n",
        "       | epoch   9 |   500/ 1782 batches | accuracy    0.942\n",
        "       | epoch   9 |  1000/ 1782 batches | accuracy    0.941\n",
        "       | epoch   9 |  1500/ 1782 batches | accuracy    0.942\n",
        "       -----------------------------------------------------------\n",
        "         end of epoch   9 | time:  8.16s | valid accuracy    0.904\n",
        "       -----------------------------------------------------------\n",
        "       | epoch  10 |   500/ 1782 batches | accuracy    0.940\n",
        "       | epoch  10 |  1000/ 1782 batches | accuracy    0.942\n",
        "       | epoch  10 |  1500/ 1782 batches | accuracy    0.942\n",
        "       -----------------------------------------------------------\n",
        "       | end of epoch  10 | time:  8.15s | valid accuracy    0.904\n",
        "       -----------------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the model with test dataset\n",
        "------------------------------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking the results of the test dataset…\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking the results of test dataset.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Token representable not found and default index is not set",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mChecking the results of test dataset.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=1'>2</a>\u001b[0m accu_test \u001b[39m=\u001b[39m evaluate(test_dataloader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtest accuracy \u001b[39m\u001b[39m{:8.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(accu_test))\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 33\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=27'>28</a>\u001b[0m total_acc, total_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=30'>31</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (label, text, offsets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=31'>32</a>\u001b[0m         predited_label \u001b[39m=\u001b[39m model(text, offsets)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=32'>33</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(predited_label, label)\n",
            "File \u001b[1;32mc:\\Users\\waqasali\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\waqasali\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\waqasali\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 33\u001b[0m in \u001b[0;36mcollate_batch\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m (_label, _text) \u001b[39min\u001b[39;00m batch:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=6'>7</a>\u001b[0m      label_list\u001b[39m.\u001b[39mappend(label_pipeline(_label))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=7'>8</a>\u001b[0m      processed_text \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(text_pipeline(_text), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=8'>9</a>\u001b[0m      text_list\u001b[39m.\u001b[39mappend(processed_text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=9'>10</a>\u001b[0m      offsets\u001b[39m.\u001b[39mappend(processed_text\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 33\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=0'>1</a>\u001b[0m text_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenizer(x)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=1'>2</a>\u001b[0m label_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(x)\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 33\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=0'>1</a>\u001b[0m text_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenizer(x)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000032?line=1'>2</a>\u001b[0m label_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(x)\n",
            "File \u001b[1;32mc:\\Users\\waqasali\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\vocab\\vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mexport\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, token: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m     58\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab[token]\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Token representable not found and default index is not set"
          ]
        }
      ],
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::\n",
        "\n",
        "       test accuracy    0.906\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test on a random news\n",
        "---------------------\n",
        "\n",
        "Use the best model so far and test a golf news.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Token – not found and default index is not set",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=11'>12</a>\u001b[0m ex_text_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMEMPHIS, Tenn. – Four days ago, Jon Rahm was \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=12'>13</a>\u001b[0m \u001b[39m    enduring the season’s worst weather conditions on Sunday at The \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=13'>14</a>\u001b[0m \u001b[39m    Open on his way to a closing 75 at Royal Portrush, which \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=20'>21</a>\u001b[0m \u001b[39m    was even more impressive considering he’d never played the \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=21'>22</a>\u001b[0m \u001b[39m    front nine at TPC Southwind.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=23'>24</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThis is a \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m news\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39mag_news_label[predict(ex_text_str, text_pipeline)])\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 27\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(text, text_pipeline)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(text, text_pipeline):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=6'>7</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=7'>8</a>\u001b[0m         text \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(text_pipeline(text))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=8'>9</a>\u001b[0m         output \u001b[39m=\u001b[39m model(text, torch\u001b[39m.\u001b[39mtensor([\u001b[39m0\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=9'>10</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 27\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=0'>1</a>\u001b[0m text_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenizer(x)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=1'>2</a>\u001b[0m label_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
            "\u001b[1;32mc:\\Users\\waqasali\\OneDrive - Intel Corporation\\Documents\\MIDS\\W207\\w207_final_project\\notebooks\\BoE_Model_v5.ipynb Cell 27\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=0'>1</a>\u001b[0m text_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: [vocab[token] \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenizer(x)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/waqasali/OneDrive%20-%20Intel%20Corporation/Documents/MIDS/W207/w207_final_project/notebooks/BoE_Model_v5.ipynb#ch0000026?line=1'>2</a>\u001b[0m label_pipeline \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\waqasali\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\vocab\\vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[1;34m(self, token)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mexport\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, token: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m     58\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab[token]\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Token – not found and default index is not set"
          ]
        }
      ],
      "source": [
        "ag_news_label = {1: \"World\",\n",
        "                 2: \"Sports\",\n",
        "                 3: \"Business\",\n",
        "                 4: \"Sci/Tec\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::\n",
        "\n",
        "       This is a Sports news\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "537e6b82cffd710c047f8e87e1af201701deab2d61e049ada42b0315ac2ac2d4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
