{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382fc24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d327ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\vibhatna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vibhatna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\vibhatna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vibhatna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vibhatna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Import\n",
    "\n",
    "import tokenizers\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers.models.deberta_v2 import DebertaV2Tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sentencepiece\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import string\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c815441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 words\n",
      "Processed 100000 words\n",
      "Processed 200000 words\n",
      "Processed 300000 words\n",
      "Processed 400000 words\n",
      "Processed 500000 words\n",
      "Processed 600000 words\n",
      "Processed 700000 words\n",
      "Processed 800000 words\n",
      "Processed 900000 words\n",
      "Processed 1000000 words\n",
      "Processed 1100000 words\n",
      "49815\n",
      "Processed 0 words\n",
      "Processed 100000 words\n",
      "Processed 200000 words\n",
      "261552\n",
      "Processed 0 words\n",
      "Processed 100000 words\n",
      "346423\n"
     ]
    }
   ],
   "source": [
    "## Creating Word Set for Not In Index\n",
    "\n",
    "word_set = {'sample'}\n",
    "\n",
    "def add_words(word_set, words):\n",
    "    index = 0\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if index % 100000 == 0:\n",
    "            print(f'Processed {index} words')\n",
    "        index += 1    \n",
    "    \n",
    "        if not word in word_set:\n",
    "            word_set.add(word)\n",
    "        \n",
    "    print(len(word_set))\n",
    "    \n",
    "add_words(word_set, brown.words())\n",
    "add_words(word_set, words.words())\n",
    "add_words(word_set, wordnet.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd83851d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "VERSION = 'v23'\n",
    "\n",
    "MAX_LEN_DISCOURSE_TEXT = 512\n",
    "TRAIN_BATCH_SIZE  = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 5\n",
    "DROP_OUT = 0.10\n",
    "TEST_SIZE = 0.1\n",
    "LEARNING_RATE = 3e-6\n",
    "\n",
    "\n",
    "BASE_MODEL = 'microsoft/deberta-v3-base'\n",
    "MODEL_PATH = './Model/model' + VERSION + '.bin'\n",
    "\n",
    "TRAINING_FILE =  '../Data/train_berkeley.csv'\n",
    "TEST_FILE = '../Data/test_berkeley.csv'\n",
    "ESSAY_FOLDER = '../feedback-prize-effectiveness/train'\n",
    "\n",
    "TOKENIZER = DebertaV2Tokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "\n",
    "CLASS_MAPPING = {\n",
    "    'Adequate': 1,\n",
    "    'Effective': 0,\n",
    "    'Ineffective' : 2\n",
    "}\n",
    "\n",
    "DISCOURSE_TYPE_MAPPING = {\n",
    "    'Lead': 0,\n",
    "    'Position': 1,\n",
    "    'Claim' : 2,\n",
    "    'Evidence' : 3,\n",
    "    'Counterclaim' : 4,\n",
    "    'Rebuttal' : 5,\n",
    "    'Concluding Statement' : 6\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.empty_cache()\n",
    "print(f'Device: {device}')\n",
    "\n",
    "GPT_MODEL_ID = 'gpt2'  # can also change to gpt-2 large if size is not an issue\n",
    "GPT_MODEL = GPT2LMHeadModel.from_pretrained(GPT_MODEL_ID).to(device)\n",
    "GPT_TOKENIZER = GPT2TokenizerFast.from_pretrained(GPT_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba88b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "\n",
    "class BERTDataset:\n",
    "    def __init__(self, discourse_texts, discourse_types, essay_ids, targets, essay_folder, max_len_discourse_text, word_set, discourse_types_text):\n",
    "        self.discourse_texts = discourse_texts\n",
    "        self.discourse_types = discourse_types\n",
    "        self.discourse_types_text = discourse_types_text\n",
    "        self.targets = targets\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.essay_ids = essay_ids\n",
    "        self.max_len_discourse_text = max_len_discourse_text        \n",
    "        self.essay_folder = essay_folder\n",
    "        self.word_set = word_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.discourse_texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        discourse_text = str(self.discourse_texts[item])\n",
    "        discourse_type = self.discourse_types[item]        \n",
    "        discourse_type_text = self.discourse_types_text[item]\n",
    "\n",
    "        # Counting Spelling errors in Text\n",
    "        text = discourse_text\n",
    "        text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "        text = text.lower()\n",
    "        tokens = word_tokenize(text)\n",
    "    \n",
    "        count = 0\n",
    "        for token in tokens:            \n",
    "            if not token in word_set and not str.isdigit(token):\n",
    "                token_stem = ps.stem(token)\n",
    "                if not token_stem in word_set:\n",
    "                    count += 1\n",
    "        \n",
    "        nii_count_discourse_text = (count - 0.85) / 1.70\n",
    "        \n",
    "        gpt_encodings = GPT_TOKENIZER(discourse_text, return_tensors='pt')\n",
    "        gpt_input_ids = gpt_encodings.input_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            gpt_outputs = GPT_MODEL(gpt_input_ids, labels=gpt_input_ids)\n",
    "            perplexity =  float(torch.exp(gpt_outputs[0]))\n",
    "            perplexity = (perplexity - 230) / 1578\n",
    "        \n",
    "        \n",
    "        essay_id = self.essay_ids[item]\n",
    "        essay_path = os.path.join(self.essay_folder, f\"{essay_id}.txt\")\n",
    "        essay = open(essay_path, 'r').read()\n",
    "        \n",
    "        input_text = discourse_type_text + \" \" + self.tokenizer.sep_token + discourse_text + \" \" + self.tokenizer.sep_token + \" \" + essay\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            input_text,\n",
    "            add_special_tokens=True,            \n",
    "            max_length=self.max_len_discourse_text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask = True\n",
    "        )\n",
    "\n",
    "        ids = inputs.input_ids.flatten()\n",
    "        mask = inputs.attention_mask.flatten() \n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'discourse_type': torch.tensor(discourse_type, dtype=torch.long),\n",
    "            'target': torch.tensor(self.targets[item], dtype=torch.long),\n",
    "            'nii_count_discourse_text': torch.tensor(nii_count_discourse_text, dtype=torch.float),\n",
    "            'perplexity': torch.tensor(perplexity, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af1c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()  \n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)   \n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.config = AutoConfig.from_pretrained(BASE_MODEL, output_hidden_states=True)\n",
    "        self.model = AutoModel.from_pretrained(BASE_MODEL, config=self.config) \n",
    "        self.mpool = MeanPooling()\n",
    "        self.dropout = nn.Dropout(DROP_OUT)\n",
    "        self.hidden = nn.Linear(777, 128)\n",
    "        self.out = nn.Linear(128, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, ids, mask, discourse_type, nii_count_discourse_text, perplexity):\n",
    "        \n",
    "        discourse_text_output = self.model(input_ids=ids, attention_mask=mask)\n",
    "        discourse_text_hidden_states = self.mpool(discourse_text_output.last_hidden_state, mask)\n",
    "        model_output_discourse_text = self.dropout(discourse_text_hidden_states)\n",
    "        \n",
    "        discourse_type_output = F.one_hot(discourse_type, num_classes=len(DISCOURSE_TYPE_MAPPING))        \n",
    "        nii_count_discourse_text  = nii_count_discourse_text.view(-1,1)        \n",
    "        perplexity = perplexity.view(-1,1)\n",
    "        \n",
    "        merged_output = torch.cat((model_output_discourse_text,                                   \n",
    "                                   discourse_type_output,\n",
    "                                   nii_count_discourse_text,\n",
    "                                   perplexity), dim=1)      \n",
    "        \n",
    "        hidden = self.hidden(merged_output)\n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ab79bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in Train: 33297\n",
      "Total samples in Validation: 3468\n",
      "Total Batches in Train: 8325\n",
      "Total Batches in Valid: 1734\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAINING_FILE)\n",
    "df_train['label'] = df_train.discourse_effectiveness\n",
    "df_train.label = df_train.label.map(CLASS_MAPPING)\n",
    "df_train['discourse_type_int'] = df_train.discourse_type\n",
    "df_train.discourse_type_int = df_train.discourse_type_int.map(DISCOURSE_TYPE_MAPPING)\n",
    "print(f'Total samples in Train: {len(df_train)}')\n",
    "\n",
    "\n",
    "df_valid = pd.read_csv(TEST_FILE)\n",
    "df_valid['label'] = df_valid.discourse_effectiveness\n",
    "df_valid.label = df_valid.label.map(CLASS_MAPPING)\n",
    "df_valid['discourse_type_int'] = df_valid.discourse_type\n",
    "df_valid.discourse_type_int = df_valid.discourse_type_int.map(DISCOURSE_TYPE_MAPPING)\n",
    "print(f'Total samples in Validation: {len(df_valid)}')\n",
    "\n",
    "\n",
    "train_dataset = BERTDataset(\n",
    "    discourse_texts=df_train.discourse_text.values,\n",
    "    essay_ids = df_train.essay_id.values,\n",
    "    targets=df_train.label.values,\n",
    "    discourse_types = df_train.discourse_type_int.values,\n",
    "    essay_folder = ESSAY_FOLDER,\n",
    "    max_len_discourse_text = MAX_LEN_DISCOURSE_TEXT,\n",
    "    word_set = word_set,\n",
    "    discourse_types_text = df_train.discourse_type.values\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_dataset = BERTDataset(\n",
    "    discourse_texts=df_valid.discourse_text.values,\n",
    "    essay_ids = df_valid.essay_id.values,\n",
    "    targets=df_valid.label.values,\n",
    "    discourse_types = df_valid.discourse_type_int.values,\n",
    "    essay_folder = ESSAY_FOLDER,\n",
    "    max_len_discourse_text = MAX_LEN_DISCOURSE_TEXT,\n",
    "    word_set = word_set,\n",
    "    discourse_types_text = df_valid.discourse_type.values\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=VALID_BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Total Batches in Train: {len(train_data_loader)}')\n",
    "print(f'Total Batches in Valid: {len(valid_data_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea72bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output, target):\n",
    "    return nn.CrossEntropyLoss()(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dc5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTBaseUncased()\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.005,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "optimizer = AdamW(optimizer_parameters, lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=num_train_steps\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_accuracy = 0.0\n",
    "total_valid_loss = 0.0\n",
    "total_train_loss = 0.0\n",
    "print(f'Model Training Started')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "        \n",
    "    total_train_loss = 0.0\n",
    "    # Train Function\n",
    "    \n",
    "    for batch_index, data in tqdm(enumerate(train_data_loader), total=len(train_data_loader)):\n",
    "        ids = data['ids']\n",
    "        mask = data['mask']\n",
    "        target = data['target']        \n",
    "        discourse_type = data['discourse_type']\n",
    "        nii_count_discourse_text= data['nii_count_discourse_text']\n",
    "        perplexity = data['perplexity']\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        target = target.to(device, dtype=torch.long)\n",
    "        discourse_type = discourse_type.to(device, dtype=torch.long)\n",
    "        nii_count_discourse_text = nii_count_discourse_text.to(device, dtype=torch.float)\n",
    "        perplexity = perplexity.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            discourse_type=discourse_type,\n",
    "            nii_count_discourse_text=nii_count_discourse_text,\n",
    "            perplexity=perplexity\n",
    "        )\n",
    "        \n",
    "        loss = loss_fn(output, target)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    \n",
    "    total_valid_loss = 0.0    \n",
    "    total_correct = 0\n",
    "    kaggle_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_index, data in tqdm(enumerate(valid_data_loader), total=len(valid_data_loader)):\n",
    "            ids = data['ids']\n",
    "            mask = data['mask']\n",
    "            target = data['target']        \n",
    "            discourse_type = data['discourse_type']\n",
    "            nii_count_discourse_text= data['nii_count_discourse_text']\n",
    "            perplexity = data['perplexity']\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            target = target.to(device, dtype=torch.long)\n",
    "            discourse_type = discourse_type.to(device, dtype=torch.long)\n",
    "            nii_count_discourse_text = nii_count_discourse_text.to(device, dtype=torch.float)\n",
    "            perplexity = perplexity.to(device, dtype=torch.float)\n",
    "\n",
    "            output = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                discourse_type=discourse_type,\n",
    "                nii_count_discourse_text=nii_count_discourse_text,\n",
    "                perplexity=perplexity         \n",
    "            )\n",
    "\n",
    "            output = torch.softmax(output, dim=1)\n",
    "            output_sum = torch.sum(output, dim=1)\n",
    "            for batch_index in range(len(target)):\n",
    "                kaggle_loss += -1 * torch.log(output[batch_index][target[batch_index]] / output_sum[batch_index])\n",
    "\n",
    "\n",
    "            validloss = loss_fn(output, target)\n",
    "            total_valid_loss += validloss.item()\n",
    "            \n",
    "            labels_prediction_conf, labels_prediction_class = torch.max(output, 1)\n",
    "            total_correct += torch.sum(labels_prediction_class == target).item()\n",
    "            validation_accuracy = total_correct / len(valid_dataset)\n",
    "        \n",
    "        \n",
    "        total_valid_loss = total_valid_loss / len(valid_data_loader)\n",
    "        total_train_loss = total_train_loss / len(train_data_loader)        \n",
    "        print(f'Epoch: {epoch + 1} :: Training Loss: {total_train_loss:.4f}, Validation Loss: {total_valid_loss:.4f}, Validation Accuracy: {validation_accuracy:.4f}')\n",
    "        print(f'Kaggle Loss: {kaggle_loss / len(valid_dataset):.4f}')        \n",
    "        \n",
    "        \n",
    "        if validation_accuracy > best_accuracy:\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            best_accuracy = validation_accuracy\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a21969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0aecca67c4464683dbc42c713d4476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vibhatna\\AppData\\Local\\Temp\\ipykernel_9080\\3851347274.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(ids, dtype=torch.long),\n",
      "C:\\Users\\vibhatna\\AppData\\Local\\Temp\\ipykernel_9080\\3851347274.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(mask, dtype=torch.long),\n",
      "C:\\Users\\vibhatna\\AppData\\Local\\Temp\\ipykernel_9080\\4247249423.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['discourse_type_prediction'][index] = prediction.item()\n",
      "C:\\Users\\vibhatna\\AppData\\Local\\Temp\\ipykernel_9080\\4247249423.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid['discourse_type_prediction_confidence'][index] = labels_prediction_conf[i].item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7099\n",
      "Kaggle Loss: 0.6580\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "kaggle_loss = 0\n",
    "\n",
    "loaded_model = BERTBaseUncased()\n",
    "loaded_model.to(device)\n",
    "loaded_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "loaded_model.eval()\n",
    "\n",
    "index = 0\n",
    "df_valid['discourse_type_prediction'] = 'Missing Prediction'\n",
    "df_valid['discourse_type_prediction_confidence'] = 'Missing Confidence'\n",
    "with torch.no_grad():\n",
    "        for batch_index, data in tqdm(enumerate(valid_data_loader), total=len(valid_data_loader)):\n",
    "            ids = data['ids']\n",
    "            mask = data['mask']\n",
    "            target = data['target']        \n",
    "            discourse_type = data['discourse_type']\n",
    "            nii_count_discourse_text= data['nii_count_discourse_text']\n",
    "            perplexity = data['perplexity']\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            target = target.to(device, dtype=torch.long)\n",
    "            discourse_type = discourse_type.to(device, dtype=torch.long)\n",
    "            nii_count_discourse_text = nii_count_discourse_text.to(device, dtype=torch.float)\n",
    "            perplexity = perplexity.to(device, dtype=torch.float)\n",
    "\n",
    "            output = loaded_model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                discourse_type=discourse_type,\n",
    "                nii_count_discourse_text=nii_count_discourse_text,\n",
    "                perplexity=perplexity         \n",
    "            )\n",
    "\n",
    "            \n",
    "            output = torch.softmax(output, dim=1)\n",
    "            output_sum = torch.sum(output, dim=1)\n",
    "            for batch_index in range(len(target)):\n",
    "                kaggle_loss += -1 * torch.log(output[batch_index][target[batch_index]] / output_sum[batch_index])              \n",
    "                \n",
    "            \n",
    "            \n",
    "            labels_prediction_conf, labels_prediction_class = torch.max(output, 1)\n",
    "            total_correct += torch.sum(labels_prediction_class == target).item()\n",
    "            \n",
    "            \n",
    "            for i,prediction in enumerate(labels_prediction_class):\n",
    "                df_valid['discourse_type_prediction'][index] = prediction.item()\n",
    "                df_valid['discourse_type_prediction_confidence'][index] = labels_prediction_conf[i].item()\n",
    "                index += 1\n",
    "            \n",
    "            \n",
    "        print(f'Model Accuracy: {total_correct / len(valid_dataset):.4f}') \n",
    "        print(f'Kaggle Loss: {kaggle_loss / len(valid_dataset):.4f}') \n",
    "\n",
    "        \n",
    "df_valid.to_csv('../Data/test_berkeley_prediction-local-' + VERSION + '.csv', sep=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0976d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs229project] *",
   "language": "python",
   "name": "conda-env-cs229project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
